# Methods for Generating Random Variables {#rvar}

## Introduction

Most of the methods so-called *computational statistics* requires generation of random variables from specified probability distribution. In hand, we can spin wheels, roll a dice, or shuffle cards. The results are chosen randomly. However, we want the same things with computer. Here, `r`. As we know, computer cannot generate complete uniform random numbers. Instead, we generate **pseudo-random** numbers.

## Pseudo-random Numbers

```{definition, name = "Pseudo-random numbers"}
Sequence of values generated deterministically which have all the appearances of being independent $unif(0, 1)$ random variables, i.e.

$$x_1, x_2, \ldots, x_n \stackrel{iid}{\sim} unif(0, 1)$$
```


- behave *as if* following $unif(0, 1)$
- typically generated from an *initial seed*

### Linear congruential generator

Let $x_0, x_1, \ldots \in \mathbb{Z}_{+}$.

1. Set $x_0$ as initial seed.
2. Generate $x_n, n = 1, 2, \ldots$ recursively:
    a. $x_n = (a x_{n - 1} + c) \mod m$
    b. where $a, c \in \mathbb{Z}_{+}, m: \text{modulus}$
3. Compute $u_n = \frac{x_n}{m} \in (0, 1)$

Then $u_1, u_2, \ldots \sim unif(0, 1)$


```{r}
lcg <- function(n, seed, a, b, m) {
  x <- rep(seed, n + 1)
  for (i in 1:n) {
    x[i + 1] <- (a * x[i] + b) %% m
  }
  x[-1] / m
}
```

```{r}
tibble(
  x = lcg(1000, 0, 1664525, 1013904223, 2^32)
) %>% 
  ggplot(aes(x = x)) +
  geom_histogram(aes(y = ..density..), bins = 30, col = gg_hcl(1))
```



### Multiplicative congruential generator

As we can expect from its name, this is congruential generator with $c = 0$.

1. Set $x_0$ as initial seed.
2. Generate $x_n, n = 1, 2, \ldots$ recursively:
    a. $x_n = a x_{n - 1} \mod m$
    b. where $a \in \mathbb{Z}_{+}, m: \text{modulus}$
3. Compute $u_n = \frac{x_n}{m} \in (0, 1)$

Then $u_1, u_2, \ldots \sim unif(0, 1)$

We just set `b = 0` in our `lcg()` function. The **seed must not be zero**.

```{r}
tibble(
  x = lcg(1000, 5, 1664525, 0, 2^32)
) %>% 
  ggplot(aes(x = x)) +
  geom_histogram(aes(y = ..density..), bins = 30, col = gg_hcl(1))
```

### Cycle

Generate LCG $n = 32$ with $a = 1$, $c = 1$, and $m = 16$ from the seed $x_0 = 0$.

```{r}
lcg(32, 0, 1, 1, 16)
```

Observe that we have the cycle after $m$-th number. Against this problem, we give different seed from every $(im + 1)$th random number.


## The Inverse Transform Method

```{definition, icdf, name = "Inverse of CDF"}
Since some cdf $F_X$ is not strictly increasing, we difine $F_X^{-1}(y)$ for $0 < y < 1$ by

$$F_{X}^{-1}(y) := inf \{ x : F_X(x) \ge y \}$$
```

Using this definition, we can get the following theorem.

```{theorem, probint, name = "Probability Integral Transformation"}
If $X$ is a continuous random variable with cdf $F_(x)$, then
$$U \equiv F_X(X) \sim unif(0, 1)$$
```

```{proof, name = "Probability Integral Transformation"}
Let $U \sim unif(0, 1)$. Then

\begin{equation*}
  \begin{split}
    P(F_X^{-1}(U) \le x) & = P(\inf\{t : F_X(t) = U \} \le x) \\
    & = P(U \le F_X(x)) \\
    & = F_U(F_X(x)) \\
    & = F_X(x)
  \end{split}
\end{equation*}
```

Thus, to generate $n$ random variables $\sim F_X$,

1. form of $F_X^{-1}(u)$
2. For each $i = 1, 2, \ldots, n$:
    a. Generate $u_i \sim unif(0, 1)$
    b. $x_i = F_X^{-1}(u_i)$

Collect $x_1, x_2, \ldots, x_n \stackrel{iid}{\sim} F_X$.

### Continuous case

Denote that the *probability integral transformation* holds for a continuous variable. When generating continuous random variable, applying above algorithm might work.

```{example, expon, name = "Exponential distribution"}
If $X \sim Exp(\lambda)$, then $F_X(x) = 1 - e^{-\lambda x}$. We can derive the inverse function of cdf
$$F_X^{-1}(u) = \frac{1}{\lambda}\ln(1 - u)$$
```

Note that

$$U \sim unif(0, 1) \Leftrightarrow 1 - U \sim unif(0,1 )$$

Then we just can use $U$ instead of $1 - U$.

```{r}
inv_exp <- function(n, lambda) {
  -log(runif(n)) / lambda
}
```

If we generate $x_1, \ldots, x_{500} \sim Exp(\lambda = 1)$,

```{r cdfexp, fig.cap="Inverse Transformation: Exp(1)"}
gg_curve(dexp, from = 0, to = 10) +
  geom_histogram(
    data = tibble(x = inv_exp(500, lambda = 1)),
    aes(x = x, y = ..density..),
    bins = 30,
    fill = gg_hcl(1),
    alpha = .5
  )
```


### Discrete case

1. For each $i = 1, 2, \ldots, n$:
    a. Generate $u_i \sim unif(0, 1)$
    b. Take $x_i$ s.t. $F_X(x_{i - 1}) < U \le F_X(x_i)$

Collect $x_1, x_2, \ldots, x_n \sim F_X$.

```{r}
pmf <-
  tibble(
    x = 0:4,
    p = c(.1, .2, .2, .2, .3)
  )
```

```{r, exdis, echo=FALSE}
pmf %>% 
  t() %>% 
  knitr::kable(format = "pandoc", col.names = NULL, caption = "Example of a Discrete Random Variable")
```

```{example, dismass, name = "Discrete Random Variable"}
Consider a discrete random variable $X$ with a mass function as in Table \@ref(tab:exdis).
```

i.e.

```{r massfun, fig.cap="Probability Mass Function"}
pmf %>% 
  ggplot() +
  geom_segment(aes(x = x, y = 0, xend = x, yend = p)) +
  ylab(expression(p(x)))
```

Then we have the cdf

```{r cdfun, fig.cap="CDF of the Discrete Random Variable: Illustration for discrete case"}
pmf %>% 
  mutate(
    fx = cumsum(p),
    x_end = lead(x, default = 5),
    u = fx,
    u = ifelse(u == .5, .6, u),
    fx1 = lead(fx, default = 1),
    rand = u > fx & u <= fx1
  ) %>% 
  ggplot() +
  geom_segment(aes(x = x, y = fx, xend = x_end, yend = fx)) +
  ylab(expression(F(x))) +
  geom_segment(
    aes(x = 0, y = u, xend = x_end, yend = u, colour = rand),
    linetype = "dashed",
    arrow = arrow(length = unit(.5, "cm")),
    show.legend = FALSE
  ) +
  geom_segment(
    aes(x = x_end, y = u, xend = x_end, yend = 0, colour = rand),
    linetype = "dashed",
    arrow = arrow(length = unit(.5, "cm")),
    show.legend = FALSE
  ) +
  scale_colour_manual(
    values = c("TRUE" = gg_hcl(1), "FALSE" = "#00000000")
  )
```


Remembering the algorithm, we can implement `dplyr::case_when()` here.

```{r}
rcustom <- function(n) {
  tibble(u = runif(n)) %>% 
    mutate(
      x = case_when(
        u > 0 & u <= .1 ~ 0,
        u > .1 & u <= .3 ~ 1,
        u > .3 & u <= .5 ~ 2,
        u > .5 & u <= .7 ~ 3,
        TRUE ~ 4
      )
    ) %>% 
    select(x) %>% 
    pull()
}
```

```{r randmass, fig.cap="Generated discrete random numbers"}
tibble(
  x = rcustom(100)
) %>% 
  ggplot(aes(x = x)) +
  geom_histogram(aes(y = ..ndensity..), binwidth = .1)
```

See Figure \@ref(fig:massfun) and \@ref(fig:randmass). Comparing the two, the result can be said okay.

### Problems with inverse transformation

Examples \@ref(exm:expon) and \@ref(exm:dismass). We could generate these random numbers because we aware of

1. analytical $F_X$
2. $F^{-1}$

In practice, however, not all distribution have analytical $F$. Numerical computing might be possible, but it is not efficient. There are other approaches.


## The Acceptance-Rejection Method

Acceptance-rejection method does not require analytical form of cdf. What we need is our *target* density (or mass) function and *proposal* density (or mass) function. Target function is what we want to generate. Propsal function is of any random variable that is *easy to generate random numbers*. From this approach, we can generate any distribution while computation is not efficient.

|pdf or pmf|target or proposal|  
|:--------:|:--:|  
| $f$ | target|  
| $g$ | proposal - easy to generate random numbers |  

First of all, $g$ should satisfy that

$$spt f \subseteq spt g$$

Next, for some (pre-specified) $c > 0$

$$\forall x \in spt f : \frac{f(x)}{g(x)} \le c$$

### A-R algorithm

For $i = 1, \ldots, n$

1. $Y \sim g(Y)$
2. $U \sim unif(0, 1) \perp\!\!\!\perp Y$
3. Accept-Reject step
    a. Accept: $U \le \frac{f(Y)}{cg(Y)} \Rightarrow x_i = Y$
    b. Reject: otherwise, go to step 1

Collect $x_1, x_2, \ldots, x_n \stackrel{iid}{\sim} f(x)$.

### Efficiency

```{r arprop, echo=FALSE, fig.cap="Property of AR method"}
illust_g <- function(x) {
  dbeta(x, shape1 = 3, shape2 = 2) * 2
}
#--------------------------------------
tibble(x = seq(0, 1, length.out = 101)) %>% 
  mutate(
    fx = dbeta(x, shape1 = 3, shape2 = 2),
    cgx = illust_g(x) - fx
  ) %>% 
  gather(-x, key = "density", value = "value") %>% 
  mutate(density = factor(density, levels = c("cgx", "fx"))) %>% 
  ggplot(aes(x = x)) +
  geom_area(aes(y = value, fill = density, colour = density), position = "stack", alpha = .5) +
  geom_segment(aes(x = .3, y = 0, xend = .3, yend = illust_g(.3)), linetype = "dashed") +
  geom_segment(aes(x = .3, y = 0, xend = .3, yend = dbeta(.3, shape1 = 3, shape2 = 2)), col = I("red")) +
  scale_fill_manual(
    values = c("fx" = NA, "cgx" = gg_hcl(1))
  ) +
  labs(
    x = "y",
    y = "density"
  )
```

See Figure \@ref(fig:arprop). This illustrates the motivation of A-R method. Lower one is $f(x)$ and the upper one is $cg(x)$ which covers $f$. The algorithm takes random number from $Y \sim g$ in each recursive step $i$, which is represented as a line in the figure. We can see that

$$0 < \frac{f(x)}{cg(x)} \le 1$$














