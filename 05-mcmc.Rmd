# Markov Chain Monte Carlo Methods

Previously, we keep trying to compute

$$E h(X)$$

by generating random numbers. It is based on the law of large numbers that says

$$E h(X) \approx \sum_{i = 1}^N \frac{h(X_i)}{N}$$

The question is, when this convergence happens. Some random numbers might require expremely large $N$, while others needs affordable size. It is known that if this $\{ X_1, \ldots, X_N \}$ is *generated from Markov chain, the series converges quite fast*.

## Limiting Distribution of Markov Chain

Definition \@ref(def:dmc) presents the definition of markov chain and *markov property*.

$$P(X_{n + 1} = j \mid X_n = i, X_{n - 1} = i_{n - 1}, \ldots, X_0 = i_0) = P(X_{n + 1} = j \mid X_n = i) = P_{ij}$$

Consider discrete state space $S$.

```{definition, mctran, name = "Transition kernel"}
One-step transition matrix for discrete time markov chain on $S$ is

$$P = \begin{bmatrix} P_{ij} \end{bmatrix}$$

$n$-stem transition matrix is written as

$$P^{(n)} = \begin{bmatrix} P_{ij}^{(n)} = P(X_{n + k} = j \mid X_k = j) \end{bmatrix}$$
```

```{theorem, cke, name = "Chapmen-Kolmogorov Equation"}
For every $n, m \in \mathbb{Z}$,

$$P^{(n + m)} = P^{(n)} P^{(m)}$$
```

```{corollary, cke2}
By the Chapmen-Kolmogorov equation,

$$\forall n \in \{ 0, 1, 2, \ldots \} : \: P^{(n)} = P^n$$
```

Does Markov chain converge to same state after time has passed much enough?

$$P(\text{starts at}\: i \: \text{and ends at}\: j \: \text{state}) = \lim_{n \rightarrow \infty} P(X_n = j \mid X_0 = i) = \lim_{n \rightarrow \infty} P_{ij}^n$$

This holds when the process satisfies some conditions.

### Ergodic theorem

Let $S$ be the state of MC.

```{definition, mcperiod, name = "Aperiodicity"}
Let $i \in S$ be a state.

\begin{itemize}
  \item Period $d(i) := \gcd \{ n : P_{ii}^(n) > 0, n \in \mathbb{N} \}$
  \item A state $i$ is said to be \textbf{\textit{periodic}} $$: \Leftrightarrow d(i) > 1$$
  \item A state $i$ is said to be \textbf{\textit{aperiodic}} $$: \Leftrightarrow d(i) = 1$$
\end{itemize}
```

It is obvious that if a chain has a period, it won't be convergent.

```{definition, mcreduc, name = "Irreducibility"}
Markov chain is \textbf{\textit{irreducible}} iff it is possible to go from any state to any other state. Otherwise, it is called \textbf{\textit{reducible}}.
```

Intuitively, the states must be a *single closed communicating* class for convergence.

```{definition, mcrecc, name = "Positive recurrence"}
Markov chain is \textbf{\textit{recurrent}} iff

$$\forall i \in S : \: \text{chain starts at}\: i \: \text{and it will eventually return to}\: i \: \text{with probabbility}\: 1$$
```

When these properties - aperiodicity, irreducibility, and positive recurrent - MC can be guaranteed to be convergent provided finite moment.

```{theorem, ergodic, name = "Ergodic theorem"}
Suppose that $\{ X_i \} \sim MC$ is aperiodic, irreducible and positive recurrent with $E \lvert h(X_j) \rvert < \infty$. Then

$$\frac{1}{N} \sum_{i = 1}^N h(X_i) \stackrel{a.s}{\rightarrow} \int_{\Omega} h(X_i) \pi(X_i) dP$$

as $N \rightarrow \infty$
```

This ergodic theorem \@ref(thm:ergodic) is an MC analog to the strong law of large numbers.

### Stationary limiting distribution

Using transition kernel, we might get the limiting distribution. For example,

\begin{equation}
  \begin{split}
    \boldsymbol\pi^{(1)} & = \boldsymbol\pi^{(0)} P \\
    & = \begin{bmatrix}
      \pi_1 & \pi_2 & \pi_3
    \end{bmatrix} \begin{bmatrix}
      \pi_{11} & \pi_{12} & \pi_{13} \\
      \pi_{21} & \pi_{22} & \pi_{23} \\
      \pi_{31} & \pi_{32} & \pi_{33}
    \end{bmatrix}
  \end{split}
  (\#eq:transiter)
\end{equation}

Recursively,

\begin{equation}
  \begin{split}
    \boldsymbol\pi^{(t)} & = \boldsymbol\pi^{(t - 1)} P \\
    & = \boldsymbol\pi^{(0)} P^t
  \end{split}
  (\#eq:transiter2)
\end{equation}

```{theorem, station, name = "Stationary probabilities"}
Suppose that $\{ X_i \} \sim MC$ is aperiodic, irreducible and positive recurrent with $E \lvert h(X_j) \rvert < \infty$. Then there exists an invariant distribution $\boldsymbol\pi$ uniquely s.t.

$$
\begin{cases}
  \boldsymbol\pi = \boldsymbol\pi P \\
  \boldsymbol\pi \mathbf{1}^T = 1
\end{cases}
$$

Denote that every vector is a row vector here.
```

### Burn-in period

This kind of convergence is usually gauranted for any starting distribution, but the time varies according to its starting point. Thus, we *throw out a certain number of the first draws* so that stationarity less dependends on the starting point. It is called burn-in period.

### Thinning

Denote that MC has a dependency structure. So we jump the chain, i.e. break the dependence. However, this process is unnecessary with Ergodic theorem and increases the variance of MC estiamtes.

## Metropolis-Hastings Algorithm

*Markov Chain Monte Carlo (MCMC) Methods* includes in metropolis-hastings algorithm and gibbs sampler. In fact, gibbs sampler is a special form of the former. Here we follow the notation of @Chib:1995de.

```{definition, mcnote, name = "Density"}
In Metropolis-hastings (M-H) algorithm, we take care about the following two densities. Denote that terms and process are similar to A-R process.

\begin{enumerate}
  \item Target density $\pi(\cdot)$ density that we try to generate sample from
  \item Candidate-generating density $q(\cdot \mid \cdot)$ density that we will actually generate random sample from
\end{enumerate}
```

### Metropolis-hastings sampler

\begin{algorithm}[H] \label{alg:mhalg}
  \SetAlgoLined
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \Input{Starting point $x_0$, burn-in period $b$}
  \For{$i \leftarrow 1$ \KwTo $N$}{
    Draw a candidate distribution $Y \sim q(\cdot \mid x^{(j)})$\;
    $U \sim unif(0, 1) \ind Y$\;
    Acceptance rate $$\alpha(x^{(j)}, y) := \min \bigg(\frac{\pi(y) q(x^{(j)} \mid y)}{\pi(x^{(j)}) q(y \mid x^{(j)})}, 1 \bigg)$$\;
    \eIf{$U \le \alpha(x^{(j)}, y)$}{
      Accept so that $x^{(j + 1)} = y$\;
    }{
      Reject so that $x^{(j + 1)} = x^{(j)}$\;
    }
  }
  Draw out the first $b \; x^{(j)}$ (Burn-in)\;
  \Output{$x^{(b + 1)}, \ldots, x^{(N)}$}
  \caption{Metropolis-Hastings algorithm with burn-in period}
\end{algorithm}

```{example, mhray, name = "Rayleigh density"}
Generate a sample from a Rayleigh density

$$f(x) = \frac{x}{\sigma^2} e^{- \frac{x^2}{2 \sigma^2}}$$
```

```{r}
dray <- function(x, sd) {
  if (sd <= 0 ) stop(gettextf("%s should be positive", expression(sd)))
  ifelse(
    x >= 0,
    x / sd^2 * exp(- x^2 / (2 * sd^2)),
    0
  )
}
```

Consider $\chi^2(x^{(j)})$ as candidate. The following function calcuates acceptance rate.

```{r}
acc_mc <- function(x, y, sd = 4) {
  ( (dray(y, sd) * dchisq(x, df = y)) / (dray(x, sd) * dchisq(y, df = x)) ) %>% 
    min(1)
}
```

To enhance the speed, we register parallel backends.

```{r, message=FALSE}
MC_CORES <- future::availableCores() - 1
cl <- parallel::makeCluster(MC_CORES)
doParallel::registerDoParallel(cl, cores = MC_CORES)
parallel::clusterExport(cl, c("acc_mc", "dray"))
parallel::clusterEvalQ(cl, c(library(dplyr), library(data.table)))
```


```{r}
mc_ray <- function(N = 10000, x0, sd = 4, burn = 1000) {
  x <- x0
  y <- numeric(1L)
  acc <- numeric(1L)
  foreach(i = seq_len(N), .combine = rbind, .inorder = TRUE) %dopar% {
    y <- rchisq(1, df = x)
    acc <- runif(1) <= acc_mc(x, y, sd)
    x <- ifelse(acc, y, x)
    data.table(
      draw = i,
      acc = acc,
      x = x
    )
  } %>% 
    .[(burn + 1):(.N)]
}
```

For a better result, try *burn-in period* 2000.

```{r}
ray <- mc_ray(N = 10000, x0 = 1, sd = 4, burn = 2000)
#---------------------------------------------------
parallel::stopCluster(cl)
```

Among 8000 chain, `r ray[, .N, by = acc][2, N]` candidiate points are rejected.

```{r}
ray[,
    .N,
    by = acc]
```

Recall that A-R method have tried to elevate the acceptance rate for efficiency.

```{r raymhpath, fig.cap="M-H sampling from Chisq to target Rayleigh"}
ray %>% 
  ggplot(aes(x = draw, y = x)) +
  geom_path(aes(colour = acc, group = 1)) +
  labs(
    x = "Draw",
    colour = "Acceptance"
  ) +
  theme(legend.position = "bottom")
```

In Figure \@ref(fig:raymhpath), the short horizontal paths might be represented as rejection points.

```{r raypathpart, fig.cap="Part of a chain from M-H sampling"}
ray[3000:3500] %>% 
  ggplot(aes(x = draw, y = x)) +
  geom_path(aes(colour = acc, group = 1)) +
  labs(
    x = "Draw",
    colour = "Acceptance"
  ) +
  theme(legend.position = "bottom")
```

Now we can see how the chain is mixed.

```{r raymix, fig.cap="Metropolis-Hastings sampling mixing"}
ray %>% 
  ggplot(aes(x = draw, y = x)) +
  geom_jitter(aes(colour = x, alpha = abs(x)), show.legend = FALSE) +
  scale_colour_gradient(low = "#0091ff", high = "#f0650e") +
  xlab("Draw")
```

See Figure \@ref(fig:raymix). We can see that the random numbers are mixed well.

### Jumping distribution

Candidiate distribution is also called in that it decides where will be the chain move in the next iteration. As in A-R, we should choose this candidate $q$ such that

$$spt \pi \subseteq spt q$$

```{r jumpdist, echo=FALSE, fig.cap="Choice of candidate distribution - Rayleigh"}
tibble(x = seq(0, 20, by = .01)) %>% 
  mutate_all(
    .funs = list(
      ~dray(., sd = 4),
      ~dchisq(., df = 6)
    )
  ) %>% 
  gather(-x, key = "jumping", value = "density") %>% 
  ggplot(aes(x = x, y = density, colour = jumping)) +
  geom_path()
```

According to this jumping distribution, M-H sampler becomes *random walk M-H and independent M-H*. Theses are the famous examples among M-H samplers.

### Random walk M-H

Let the candidate distribution be a *symmetric random walk*. Then this is called random walk M-H.

\begin{equation}
  q(y \mid x) = q_1(\lvert y - x \rvert)
  (\#eq:symjump)
\end{equation}

Then

$$q(y \mid x) = q(x \mid y)$$

and hence the acceptance ratio becomes

\begin{equation}
  \alpha(x^{(j)}, y) := \min \bigg(\frac{\pi(y)}{\pi(x^{(j)})}, 1 \bigg)
  (\#eq:symacc)
\end{equation}

Here, candidate number $y$ is generated in the form of

\begin{equation}
  y = x + z
  (\#eq:symcandpt)
\end{equation}

with increment $z \sim q(\lvert z \rvert)$.

```{example, mct, name = "Random walk metropolis"}
Generate $t(\nu)$ using the random walk M-H.
```

Use the proposal distribution $N(X^{(j)}, \sigma^2)$. Denote that normal distribution is symmetric. Then

$$q(x \mid y) = q(y \mid x)$$

Thus,

$$\alpha(x^{(j)}, y) = \min \bigg(\frac{\pi(y)}{\pi(x^{(j)})}, 1 \bigg) = \min \bigg( \frac{t(y)}{t(x^{(j)})}, 1 \bigg)$$

### Independence M-H

When the candidate distribution does not depend on the previous value of the chain, it is called the *independence sampler*.

\begin{equation}
  q(y \mid x) = q(y)
  (\#eq:indepjump)
\end{equation}

Thus, the acceptance ratio is

\begin{equation}
  \alpha(x^{(j)}, y) := \min \bigg(\frac{\pi(y) q(x^{(j)})}{\pi(x^{(j)}) q(y)}, 1 \bigg)
  (\#eq:indepacc)
\end{equation}

The independence sampler is simple. Also, it gives a nice result provided that the jumping distribution is closed to the target. Otherwise, it does not perform well, which is the most case.


## Gibbs Sampler

### Concept of gibbs sampler

We are given the joint density. For this joint density, the following theorem can be proven.

```{theorem, ham, name = "Hammersley-Clifford Theorem"}
Suppose that $(X, Y)^T \sim f(x, y)$. Then

$$f(x, y) = \frac{f(y \mid x)}{\int_{\R} \frac{f(y \mid x)}{f(x \mid y)} dy}$$
```

By definition, $f(x, y) \propto f(y \mid x)$. However, the above theorem gives that this joint density is proportional to both conditional densities, i.e. also to $f(x \mid y)$.

```{corollary, hamcor}
Theorem \@ref(thm:ham) implies the second 

\begin{itemize}
  \item $f(x, y) \propto f(y \mid x)$
  \item $f(x, y) \propto f(x \mid y)$
\end{itemize}
```

This can be extended to cases more than two blocks.

```{definition, fullcond, name = "Full conditional distribution"}
Let $\mathbf{X} = (X_1, \ldots, X_p)^T \in \R^p$ be a $p$-dimensional random vector. Then the \textbf{\textit{full conditional distribution}} of $X_j$ is

$$f(X_j \mid \mathbf{X}_{(-j)})$$

where $\mathbf{X}_{(-j)} = (X_1, \ldots, X_{j - 1}, X_{j + 1}, \ldots, X_p)^T$.
```

Gibbs sampler iterate to generate a number from each full conditional distribution so that we finally get the joint density, i.e.

$$X_j \sim f(X_j \mid \mathbf{X}_{(-j)})$$

For instance, for $p = 3$,

$$
\begin{cases}
  X^{(1)} \sim f(x \mid y^{(0)}, z^{(0)}) \\
  Y^{(1)} \sim f(y \mid \color{blue}{x^{(1)}}, z^{(0)}) \\
  Z^{(1)} \sim f(z \mid \color{blue}{x^{(1)}}, \color{blue}{y^{(1)}})
\end{cases}
$$

and so $(X^{(1)}, Y^{(1)}, Z^{(1)})^T \sim f(x, y, z)$. Next,

$$
\begin{cases}
  X^{(2)} \sim f(x \mid \color{blue}{y^{(1)}}, \color{blue}{z^{(1)}}) \\
  Y^{(2)} \sim f(y \mid \color{red}{x^{(2)}}, \color{blue}{z^{(1)}}) \\
  Z^{(2)} \sim f(z \mid \color{red}{x^{(2)}}, \color{red}{y^{(2)}})
\end{cases}
$$

so that $(X^{(2)}, Y^{(2)}, Z^{(2)})^T \sim f(x, y, z)$, and so on.

### Full conditional distributions

Suppose that we only have 

Here, of course, we should know $f(\cdot \mid \cdot)$. In some cases, the closed form can be given. Otherwise, there are some calculation methods.

1. normalized posterior
2. drop the irrelevant terms
3. closed form
4. Repeat 2 and 3 for all parameter blocks

```{example, bivgibbs, name = "Bivariate normal distribution"}
Generate

$$
(X_1, X_2) \mid \mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho \sim N_2 \bigg( (\mu_1, \mu_2)^T, \begin{bmatrix}
  \sigma_1^2 & \rho \\
  \rho & \sigma_2^2
\end{bmatrix}
\bigg)
$$
```

In this problem, its closed can easily calculated.

$$
\begin{cases}
  X_1 \mid X_2, \mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho \sim N \Big( \mu_1 + \rho \frac{\sigma_1}{\sigma_2} (X_2 - \mu_2), (1 - \rho^2) \sigma_1^2 \Big) \\
  X_2 \mid X_1, \mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho \sim N \Big( \mu_2 + \rho \frac{\sigma_2}{\sigma_1} (X_1 - \mu_1), (1 - \rho^2) \sigma_2^2 \Big)
\end{cases}
$$

Hence, we just iterate the above set of process until gaining $N$ draws.

### Gibbs sampler step

\begin{algorithm}[H] \label{alg:gibbalg}
  \SetAlgoLined
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \KwData{Full conditional distribution $f$}
  \Input{Starting values $(x_1^{(0)}, x_2^{(0)})$, burn-in period $b$}
  \For{$i \leftarrow 1$ \KwTo $N$}{
    Set $x_2^{\ast} = x_2^{(i - 1)}$\;
    \For{$j \leftarrow 1$ \KwTo $2$}{
      Generate $x_j^{(i)} \sim f(x_j \mid x_{(-j)} = x_{(-j)}^{\ast})$\;
      Set or update $x_j^{\ast} = x_j^{(i)}$\;
    }
  }
  Draw out the first $b \; x^{(j)}$ (Burn-in)\;
  \Output{$x^{(b + 1)}, \ldots, x^{(N)}$}
  \caption{Gibbs-sampler steps}
\end{algorithm}

Sometimes Gibbs sampler algorithm $\ref{alg:gibbalg}$ requires nested loop, whose efficiency becomes quite awful. In `R`, `C++` implementation can be a solution [@Wickham:2019aa]. The following code is executed in `Rcpp` environment in `rmd` document. In practice, this should be placed in `cpp` file. Or `cppFunction()` can also be used.

```{Rcpp}
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
NumericMatrix gibbs_bvn(int N, double x, double y, int burn, 
                        double mu1, double mu2, double sig1, double sig2, double rho) {
  NumericMatrix mat(N - burn, 2);
  
  for(int i = 0; i < burn; i++) {
    x = rnorm(1, mu1 + rho * sig1 / sig2 * (y - mu2), (1 - pow(rho, 2)) * pow(sig1, 2))[0];
    y = rnorm(1, mu2 + rho * sig2 / sig1 * (x - mu1), (1 - pow(rho, 2)) * pow(sig2, 2))[0];
  }
  
  for(int i = burn; i < N; i++) {
    x = rnorm(1, mu1 + rho * sig1 / sig2 * (y - mu2), (1 - pow(rho, 2)) * pow(sig1, 2))[0];
    y = rnorm(1, mu2 + rho * sig2 / sig1 * (x - mu1), (1 - pow(rho, 2)) * pow(sig2, 2))[0];
    mat(i - burn, 0) = x;
    mat(i - burn, 1) = y;
  }
  
  return(mat);
}
```

By executing above code, `gibbs_bvn(N, x, y, burn, mu1, mu2, sig1, sig2, rho)` function is created.

```{r}
bvn <- 
  gibbs_bvn(5000, 0, 0, 1000, 0, 2, 1, .5, -.75) %>% 
  data.table()
setnames(bvn, c("x", "y"))
```

We have generated bivariate normal random numbers. See Figure \@ref(fig:bvnscatter). Compare with our $\boldsymbol\mu$ and $\Sigma$.

```{r bvnscatter, fig.cap="Bivariate normal chain by the gibbs sampler"}
gg_scatter(bvn, aes(x, y))
```


## Monitoring Convergence

See Figure \@ref(fig:raymhpath), a chain generated by M-H sampling. Is this convergent?

### Gelman-Rubin method

Geolman-Rubin method monitors convergence of a M-H chain. It requires *multiple chains and compare the behavior of them with respect to the variance of one or more scalar summary statistics*. The estimates of variance are similar to between- and within- mean squared erros in **one-way ANOVA**. Consider $k$ chains of length $n$, saying $\{ X_{ij} : 1 \le i \le k, 1 \le j \le n \}$. Let $\psi$ be a scalar summary statistic that estimates some parameter of the target distribution. Compute scalar summary statistic for each chain $\{ \psi_{in} = \psi(X_{i1}, \ldots, X_{in}) \}$. Then we expect that

<!-- \begin{algorithm}[H] \label{alg:gelmanalg} -->
<!--   \SetAlgoLined -->
<!--   \SetKwInOut{Input}{input} -->
<!--   \SetKwInOut{Output}{output} -->

<!--   \caption{Gelman-Rubin method} -->
<!-- \end{algorithm} -->











